{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"3\">KINGDOM OF SAUDI ARABIA<br>\n",
        "Ministry of Higher Education<br>                                  \n",
        "Al-Imam Mohammad University<br>\n",
        "College of Computer & Information Sciences<br><br>\n",
        "    \n",
        " \n",
        "**Deep Learning (CS464), Winter 22-23 - Second Semester 1444**\n",
        "<br>**Instructor:\n",
        "Dr. Haifa Alkasem**\n",
        "<br><br>\n",
        "**Prepared by:**<br>\n",
        "Raghad Albosais (440020209)<br>\n",
        "\n",
        "**Section: 371**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "fDzhBJ-NxMzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is seperate notebook from the original notebook. Since I faced a problem regarding the memory usage, during the run time of hyperparameters tunning, it full up until at certain points, it is crashe. This is due to the natural work of GridSearch, it is brute-force approaches to finding the right\n",
        "hyperparameter configurations, which is an expensive and time-consuming process. (if we have two\n",
        "parameters specified, each of with 2 values, and the folds is 3. It ends up with 2x2=4 candidate\n",
        "models, each model with 3 folds, totalling of 4x3 = 12 fit models.)\n",
        "Therefore, what I did to overcome the limited resources I have is to split the hyperparameter tunning\n",
        "into another notebook with only necessary cells to do it (without data visualization and etc.)"
      ],
      "metadata": {
        "id": "3IQ6bZC8K1GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the libraries \n",
        "\n",
        "#  enables the drawing of matplotlib figures in the IPython environment.\n",
        "%matplotlib inline\n",
        "\n",
        "# to access the path\n",
        "import os\n",
        "\n",
        "# libraries for visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# tensorflow to build and process DL model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "# library to work with dataframes\n",
        "import pandas as pd\n",
        "# library to work on array and matrcies\n",
        "import numpy as np\n",
        "# library to work on basic operation of ML project\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# libraries to download images\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# implement scikit-learn classifier API for Keras\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "# cross validation methods\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# hyperparameters tunning method\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# to ensure reproducibility of the result in each run\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "# remove messages\n",
        "import logging\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
        "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "nzz28wzouFjO",
        "gather": {
          "logged": 1674773104227
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if CUDA is available\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "train_on_gpu = tf.test.is_gpu_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnGObtr_fx-J",
        "outputId": "24844da7-2e4b-4780-9c07-02807286353d",
        "gather": {
          "logged": 1674773109740
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset"
      ],
      "metadata": {
        "id": "SgKiqvntOcn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define train, test and valid data directories\n",
        "data_dir = 'afterSplit_chest_xray'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "val_dir = os.path.join(data_dir, 'val')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "eWOBFzZQZK5G",
        "gather": {
          "logged": 1674773115733
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the images as filenames with their labels\n",
        "labels = ['NORMAL', 'PNEUMONIA']\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            if img[-4:] == 'jpeg':\n",
        "                data.append((os.path.join(path, img), class_num))\n",
        "\n",
        "    return data\n",
        "    \n",
        "train = get_data(train_dir)\n",
        "test = get_data(test_dir)\n",
        "val = get_data(val_dir)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "_67VlRWgxYx9",
        "gather": {
          "logged": 1674773122370
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the image classes\n",
        "classes = os.listdir(train_dir)\n",
        "calsses_name = dict()\n",
        "for name in classes:\n",
        "    if name == 'NORMAL':\n",
        "        calsses_name[name] = 0\n",
        "    else:\n",
        "        calsses_name[name] = 1 \n",
        "print('Num of classes: ', len(classes))\n",
        "print('Classes names: ', calsses_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of classes:  2\n",
            "Classes names:  {'PNEUMONIA': 1, 'NORMAL': 0}\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "R804KMQKQ6A7",
        "gather": {
          "logged": 1674772476706
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3df63a-ebf0-4083-9847-5b5031da20fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset as (image, label) pairs\n",
        "\n",
        "# list of class names\n",
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "\n",
        "# hyperparameter > the size of image\n",
        "img_size = 224\n",
        "# hyperparameter > the channel of image\n",
        "channel = cv2.IMREAD_COLOR\n",
        "\n",
        "# function take the directory and return the data in pairs (image, label)\n",
        "def get_data(data_dir):\n",
        "    data = []\n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "\n",
        "        for img in os.listdir(path):\n",
        "\n",
        "            if img[-4:] == 'jpeg':\n",
        "                try:\n",
        "                    img_arr = cv2.imread(os.path.join(path, img), channel)\n",
        "\n",
        "                    # ---- basic preprocessing ---- #\n",
        "                    # 1. reshaping images to preferred size\n",
        "                    resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
        "                    # 2. change to float datatype\n",
        "                    img = resized_arr.astype('float32') \n",
        "                    # 3. normalize the pixels value to lie between 0 to 1\n",
        "                    img = img / 255.0 \n",
        "\n",
        "                    data.append([img, class_num])\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "\n",
        "    return np.array(data)\n",
        "\n",
        "train_data = get_data(train_dir)\n",
        "test_data = get_data(test_dir)\n",
        "valid_data = get_data(val_dir)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674773358540
        },
        "id": "prv-ELwfxMzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# further split each pair to be x for data and y for label\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for feature, label in train_data:\n",
        "    x_train.append(feature)\n",
        "    y_train.append(label)\n",
        "\n",
        "for feature, label in test_data:\n",
        "    x_test.append(feature)\n",
        "    y_test.append(label)\n",
        "    \n",
        "for feature, label in valid_data:\n",
        "    x_val.append(feature)\n",
        "    y_val.append(label)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674773366224
        },
        "id": "amw4JTFLxMzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the lists of x and y into numpy arrays\n",
        "# so that to make it suitable as input for tensorflow methods (fit, evaluate, predict)\n",
        "x_train = np.array(x_train)\n",
        "x_val = np.array(x_val)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "y_train = np.array(y_train).reshape(len(y_train), 1)\n",
        "y_val = np.array(y_val).reshape(len(y_val),1)\n",
        "y_test = np.array(y_test).reshape(len(y_test), 1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674773372028
        },
        "id": "2KcZvvssxMzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameters tuning with k-folds"
      ],
      "metadata": {
        "id": "lrUdQMIaQOph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# combine the train and validation into one set\n",
        "X_train = np.concatenate((x_train, x_val))\n",
        "print(X_train.shape)\n",
        "\n",
        "Y_train = np.concatenate((y_train, y_val))\n",
        "print(Y_train.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674773394975
        },
        "id": "z0KYYU3ExMzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Folds cross-validator as hyperparameters tunning and evaluation for different hyperparameters values using  GridSearch and KerasClassifier."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "6coCHuYgxMzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model arichitecture and configuration\n",
        "def create_model(optimizer='adam'):\n",
        "    # create the model using sequential method, where the order of layers will be as added\n",
        "    model = Sequential()\n",
        "\n",
        "    # first conv bolck\n",
        "    # input 224x224x1, output 112x112x16\n",
        "    model.add(Conv2D(16, (3, 3), padding='same', input_shape=(img_size, img_size, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # second conv block\n",
        "    # input 112x112x16, output 56x56x32\n",
        "    model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # third conv block\n",
        "    # input 56x56x32, output 28x28x64\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # forth conv block\n",
        "    # input 28x28x64, output 14x14x128\n",
        "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # flatt the last conv block ito 1D vector\n",
        "    # input 14x14x128, output 25088\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # first FC layer\n",
        "    # input 25088, output 512\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    # second FC layer\n",
        "    # input 512, output 128\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    # third FC layer\n",
        "    # input 128, output 64\n",
        "    model.add(Dense(64))\n",
        "    model.add(Activation(\"relu\"))\n",
        "\n",
        "    # forth FC layer\n",
        "    # input 64, output 1\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "    loss = 'binary_crossentropy'\n",
        "    metrics = ['accuracy',\n",
        "    tf.keras.metrics.Precision(name='precision'), \n",
        "    tf.keras.metrics.Recall(name='recall'),\n",
        "    tf.keras.metrics.TruePositives(name='TP'),\n",
        "    tf.keras.metrics.TrueNegatives(name='TN'),\n",
        "    tf.keras.metrics.FalsePositives(name='FP'),\n",
        "    tf.keras.metrics.FalseNegatives(name='FN')]\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
        "    \n",
        "    return model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674687665377
        },
        "id": "RyDqtgfAxMzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using k fold as hyperparamer tunning \n",
        "\n",
        "# define cross-validation method\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# different variation of k fold cross validator\n",
        "skf = StratifiedKFold(n_splits=3, shuffle= True, random_state= 17)\n",
        "kf = KFold(n_splits=3, shuffle= True, random_state= 17)\n",
        "\n",
        "# define Model wihtout specifing hyperparamers value\n",
        "model3 = KerasClassifier(build_fn=create_model,\n",
        "                        verbose=1,\n",
        "                        shuffle=True)\n",
        "\n",
        "# define Hyper-parameter and its list values\n",
        "optimizer =  ['SGD', 'adam'] \n",
        "batch_size = [16, 32]\n",
        "epochs = [5, 10]\n",
        "\n",
        "param_grid = dict(optimizer=optimizer,batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# define the evaluate the performance of the cross-validated model on the test set\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import make_scorer\n",
        "scoring = make_scorer(accuracy_score)\n",
        "\n",
        "# define GridSearchCV and fit it in the model\n",
        "grid = GridSearchCV(estimator=model3, param_grid=param_grid, refit = True, scoring = scoring, cv=skf)\n",
        "grid_model = grid.fit(x_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "285/285 [==============================] - 5s 13ms/step - loss: 0.2598 - accuracy: 0.8938 - precision: 0.8815 - recall: 0.9101 - TP: 2075.0000 - TN: 1999.0000 - FP: 279.0000 - FN: 205.0000\n",
            "Epoch 2/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.1320 - accuracy: 0.9495 - precision: 0.9457 - recall: 0.9539 - TP: 2175.0000 - TN: 2153.0000 - FP: 125.0000 - FN: 105.0000\n",
            "Epoch 3/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0913 - accuracy: 0.9680 - precision: 0.9680 - recall: 0.9680 - TP: 2207.0000 - TN: 2205.0000 - FP: 73.0000 - FN: 73.0000\n",
            "Epoch 4/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0717 - accuracy: 0.9756 - precision: 0.9754 - recall: 0.9759 - TP: 2225.0000 - TN: 2222.0000 - FP: 56.0000 - FN: 55.0000\n",
            "Epoch 5/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0569 - accuracy: 0.9781 - precision: 0.9785 - recall: 0.9776 - TP: 2229.0000 - TN: 2229.0000 - FP: 49.0000 - FN: 51.0000\n",
            "72/72 [==============================] - 1s 8ms/step\n",
            "Epoch 1/5\n",
            "285/285 [==============================] - 5s 12ms/step - loss: 0.2627 - accuracy: 0.8989 - precision: 0.8925 - recall: 0.9070 - TP: 2068.0000 - TN: 2030.0000 - FP: 249.0000 - FN: 212.0000\n",
            "Epoch 2/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.1244 - accuracy: 0.9583 - precision: 0.9563 - recall: 0.9605 - TP: 2190.0000 - TN: 2179.0000 - FP: 100.0000 - FN: 90.0000\n",
            "Epoch 3/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.1073 - accuracy: 0.9629 - precision: 0.9660 - recall: 0.9596 - TP: 2188.0000 - TN: 2202.0000 - FP: 77.0000 - FN: 92.0000\n",
            "Epoch 4/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0819 - accuracy: 0.9717 - precision: 0.9715 - recall: 0.9719 - TP: 2216.0000 - TN: 2214.0000 - FP: 65.0000 - FN: 64.0000\n",
            "Epoch 5/5\n",
            "285/285 [==============================] - 4s 12ms/step - loss: 0.0661 - accuracy: 0.9741 - precision: 0.9729 - recall: 0.9754 - TP: 2224.0000 - TN: 2217.0000 - FP: 62.0000 - FN: 56.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "285/285 [==============================] - 5s 12ms/step - loss: 0.2651 - accuracy: 0.8969 - precision: 0.8819 - recall: 0.9167 - TP: 2090.0000 - TN: 1999.0000 - FP: 280.0000 - FN: 190.0000\n",
            "Epoch 2/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.1217 - accuracy: 0.9487 - precision: 0.9471 - recall: 0.9504 - TP: 2167.0000 - TN: 2158.0000 - FP: 121.0000 - FN: 113.0000\n",
            "Epoch 3/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0871 - accuracy: 0.9673 - precision: 0.9684 - recall: 0.9662 - TP: 2203.0000 - TN: 2207.0000 - FP: 72.0000 - FN: 77.0000\n",
            "Epoch 4/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0684 - accuracy: 0.9741 - precision: 0.9766 - recall: 0.9715 - TP: 2215.0000 - TN: 2226.0000 - FP: 53.0000 - FN: 65.0000\n",
            "Epoch 5/5\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0518 - accuracy: 0.9803 - precision: 0.9824 - recall: 0.9781 - TP: 2230.0000 - TN: 2239.0000 - FP: 40.0000 - FN: 50.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "285/285 [==============================] - 6s 13ms/step - loss: 0.4633 - accuracy: 0.8982 - precision: 0.8982 - recall: 0.8982 - TP: 2048.0000 - TN: 2046.0000 - FP: 232.0000 - FN: 232.0000\n",
            "Epoch 2/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.2139 - accuracy: 0.9291 - precision: 0.9290 - recall: 0.9294 - TP: 2119.0000 - TN: 2116.0000 - FP: 162.0000 - FN: 161.0000\n",
            "Epoch 3/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1253 - accuracy: 0.9566 - precision: 0.9562 - recall: 0.9570 - TP: 2182.0000 - TN: 2178.0000 - FP: 100.0000 - FN: 98.0000\n",
            "Epoch 4/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1160 - accuracy: 0.9557 - precision: 0.9565 - recall: 0.9548 - TP: 2177.0000 - TN: 2179.0000 - FP: 99.0000 - FN: 103.0000\n",
            "Epoch 5/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1009 - accuracy: 0.9642 - precision: 0.9657 - recall: 0.9627 - TP: 2195.0000 - TN: 2200.0000 - FP: 78.0000 - FN: 85.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "285/285 [==============================] - 5s 13ms/step - loss: 0.5962 - accuracy: 0.8776 - precision: 0.8770 - recall: 0.8785 - TP: 2003.0000 - TN: 1998.0000 - FP: 281.0000 - FN: 277.0000\n",
            "Epoch 2/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1633 - accuracy: 0.9406 - precision: 0.9400 - recall: 0.9412 - TP: 2146.0000 - TN: 2142.0000 - FP: 137.0000 - FN: 134.0000\n",
            "Epoch 3/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1489 - accuracy: 0.9447 - precision: 0.9467 - recall: 0.9425 - TP: 2149.0000 - TN: 2158.0000 - FP: 121.0000 - FN: 131.0000\n",
            "Epoch 4/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1080 - accuracy: 0.9583 - precision: 0.9604 - recall: 0.9561 - TP: 2180.0000 - TN: 2189.0000 - FP: 90.0000 - FN: 100.0000\n",
            "Epoch 5/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0942 - accuracy: 0.9651 - precision: 0.9662 - recall: 0.9640 - TP: 2198.0000 - TN: 2202.0000 - FP: 77.0000 - FN: 82.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "285/285 [==============================] - 5s 13ms/step - loss: 0.5294 - accuracy: 0.8967 - precision: 0.8976 - recall: 0.8956 - TP: 2042.0000 - TN: 2046.0000 - FP: 233.0000 - FN: 238.0000\n",
            "Epoch 2/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1687 - accuracy: 0.9381 - precision: 0.9385 - recall: 0.9377 - TP: 2138.0000 - TN: 2139.0000 - FP: 140.0000 - FN: 142.0000\n",
            "Epoch 3/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1209 - accuracy: 0.9572 - precision: 0.9562 - recall: 0.9583 - TP: 2185.0000 - TN: 2179.0000 - FP: 100.0000 - FN: 95.0000\n",
            "Epoch 4/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1178 - accuracy: 0.9548 - precision: 0.9556 - recall: 0.9539 - TP: 2175.0000 - TN: 2178.0000 - FP: 101.0000 - FN: 105.0000\n",
            "Epoch 5/5\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1113 - accuracy: 0.9631 - precision: 0.9636 - recall: 0.9627 - TP: 2195.0000 - TN: 2196.0000 - FP: 83.0000 - FN: 85.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "285/285 [==============================] - 5s 12ms/step - loss: 0.2678 - accuracy: 0.8892 - precision: 0.8798 - recall: 0.9018 - TP: 2056.0000 - TN: 1997.0000 - FP: 281.0000 - FN: 224.0000\n",
            "Epoch 2/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.1418 - accuracy: 0.9465 - precision: 0.9438 - recall: 0.9496 - TP: 2165.0000 - TN: 2149.0000 - FP: 129.0000 - FN: 115.0000\n",
            "Epoch 3/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0988 - accuracy: 0.9647 - precision: 0.9633 - recall: 0.9662 - TP: 2203.0000 - TN: 2194.0000 - FP: 84.0000 - FN: 77.0000\n",
            "Epoch 4/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0798 - accuracy: 0.9719 - precision: 0.9707 - recall: 0.9732 - TP: 2219.0000 - TN: 2211.0000 - FP: 67.0000 - FN: 61.0000\n",
            "Epoch 5/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0598 - accuracy: 0.9792 - precision: 0.9815 - recall: 0.9768 - TP: 2227.0000 - TN: 2236.0000 - FP: 42.0000 - FN: 53.0000\n",
            "Epoch 6/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0471 - accuracy: 0.9818 - precision: 0.9833 - recall: 0.9803 - TP: 2235.0000 - TN: 2240.0000 - FP: 38.0000 - FN: 45.0000\n",
            "Epoch 7/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0415 - accuracy: 0.9840 - precision: 0.9863 - recall: 0.9816 - TP: 2238.0000 - TN: 2247.0000 - FP: 31.0000 - FN: 42.0000\n",
            "Epoch 8/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0299 - accuracy: 0.9882 - precision: 0.9890 - recall: 0.9873 - TP: 2251.0000 - TN: 2253.0000 - FP: 25.0000 - FN: 29.0000\n",
            "Epoch 9/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0337 - accuracy: 0.9875 - precision: 0.9894 - recall: 0.9855 - TP: 2247.0000 - TN: 2254.0000 - FP: 24.0000 - FN: 33.0000\n",
            "Epoch 10/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0209 - accuracy: 0.9928 - precision: 0.9938 - recall: 0.9917 - TP: 2261.0000 - TN: 2264.0000 - FP: 14.0000 - FN: 19.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "285/285 [==============================] - 5s 12ms/step - loss: 0.2685 - accuracy: 0.8914 - precision: 0.8787 - recall: 0.9083 - TP: 2071.0000 - TN: 1993.0000 - FP: 286.0000 - FN: 209.0000\n",
            "Epoch 2/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.1252 - accuracy: 0.9557 - precision: 0.9506 - recall: 0.9614 - TP: 2192.0000 - TN: 2165.0000 - FP: 114.0000 - FN: 88.0000\n",
            "Epoch 3/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.1097 - accuracy: 0.9625 - precision: 0.9647 - recall: 0.9601 - TP: 2189.0000 - TN: 2199.0000 - FP: 80.0000 - FN: 91.0000\n",
            "Epoch 4/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0912 - accuracy: 0.9669 - precision: 0.9675 - recall: 0.9662 - TP: 2203.0000 - TN: 2205.0000 - FP: 74.0000 - FN: 77.0000\n",
            "Epoch 5/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0663 - accuracy: 0.9774 - precision: 0.9785 - recall: 0.9763 - TP: 2226.0000 - TN: 2230.0000 - FP: 49.0000 - FN: 54.0000\n",
            "Epoch 6/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0571 - accuracy: 0.9792 - precision: 0.9815 - recall: 0.9768 - TP: 2227.0000 - TN: 2237.0000 - FP: 42.0000 - FN: 53.0000\n",
            "Epoch 7/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0408 - accuracy: 0.9855 - precision: 0.9868 - recall: 0.9842 - TP: 2244.0000 - TN: 2249.0000 - FP: 30.0000 - FN: 36.0000\n",
            "Epoch 8/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0403 - accuracy: 0.9849 - precision: 0.9864 - recall: 0.9833 - TP: 2242.0000 - TN: 2248.0000 - FP: 31.0000 - FN: 38.0000\n",
            "Epoch 9/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0278 - accuracy: 0.9901 - precision: 0.9921 - recall: 0.9882 - TP: 2253.0000 - TN: 2261.0000 - FP: 18.0000 - FN: 27.0000\n",
            "Epoch 10/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0226 - accuracy: 0.9917 - precision: 0.9938 - recall: 0.9895 - TP: 2256.0000 - TN: 2265.0000 - FP: 14.0000 - FN: 24.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "285/285 [==============================] - 5s 12ms/step - loss: 0.2687 - accuracy: 0.8930 - precision: 0.8823 - recall: 0.9070 - TP: 2068.0000 - TN: 2003.0000 - FP: 276.0000 - FN: 212.0000\n",
            "Epoch 2/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.1195 - accuracy: 0.9511 - precision: 0.9489 - recall: 0.9535 - TP: 2174.0000 - TN: 2162.0000 - FP: 117.0000 - FN: 106.0000\n",
            "Epoch 3/10\n",
            "285/285 [==============================] - 4s 12ms/step - loss: 0.0792 - accuracy: 0.9691 - precision: 0.9709 - recall: 0.9671 - TP: 2205.0000 - TN: 2213.0000 - FP: 66.0000 - FN: 75.0000\n",
            "Epoch 4/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0653 - accuracy: 0.9719 - precision: 0.9736 - recall: 0.9702 - TP: 2212.0000 - TN: 2219.0000 - FP: 60.0000 - FN: 68.0000\n",
            "Epoch 5/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0477 - accuracy: 0.9805 - precision: 0.9828 - recall: 0.9781 - TP: 2230.0000 - TN: 2240.0000 - FP: 39.0000 - FN: 50.0000\n",
            "Epoch 6/10\n",
            "285/285 [==============================] - 4s 12ms/step - loss: 0.0337 - accuracy: 0.9879 - precision: 0.9903 - recall: 0.9855 - TP: 2247.0000 - TN: 2257.0000 - FP: 22.0000 - FN: 33.0000\n",
            "Epoch 7/10\n",
            "285/285 [==============================] - 4s 12ms/step - loss: 0.0241 - accuracy: 0.9914 - precision: 0.9934 - recall: 0.9895 - TP: 2256.0000 - TN: 2264.0000 - FP: 15.0000 - FN: 24.0000\n",
            "Epoch 8/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0256 - accuracy: 0.9917 - precision: 0.9917 - recall: 0.9917 - TP: 2261.0000 - TN: 2260.0000 - FP: 19.0000 - FN: 19.0000\n",
            "Epoch 9/10\n",
            "285/285 [==============================] - 3s 12ms/step - loss: 0.0173 - accuracy: 0.9930 - precision: 0.9943 - recall: 0.9917 - TP: 2261.0000 - TN: 2266.0000 - FP: 13.0000 - FN: 19.0000\n",
            "Epoch 10/10\n",
            "285/285 [==============================] - 4s 12ms/step - loss: 0.0069 - accuracy: 0.9985 - precision: 0.9991 - recall: 0.9978 - TP: 2275.0000 - TN: 2277.0000 - FP: 2.0000 - FN: 5.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "285/285 [==============================] - 5s 13ms/step - loss: 0.5585 - accuracy: 0.8800 - precision: 0.8756 - recall: 0.8860 - TP: 2020.0000 - TN: 1991.0000 - FP: 287.0000 - FN: 260.0000\n",
            "Epoch 2/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1963 - accuracy: 0.9320 - precision: 0.9328 - recall: 0.9311 - TP: 2123.0000 - TN: 2125.0000 - FP: 153.0000 - FN: 157.0000\n",
            "Epoch 3/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1267 - accuracy: 0.9522 - precision: 0.9518 - recall: 0.9526 - TP: 2172.0000 - TN: 2168.0000 - FP: 110.0000 - FN: 108.0000\n",
            "Epoch 4/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0977 - accuracy: 0.9649 - precision: 0.9641 - recall: 0.9658 - TP: 2202.0000 - TN: 2196.0000 - FP: 82.0000 - FN: 78.0000\n",
            "Epoch 5/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0919 - accuracy: 0.9660 - precision: 0.9654 - recall: 0.9667 - TP: 2204.0000 - TN: 2199.0000 - FP: 79.0000 - FN: 76.0000\n",
            "Epoch 6/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0703 - accuracy: 0.9746 - precision: 0.9758 - recall: 0.9732 - TP: 2219.0000 - TN: 2223.0000 - FP: 55.0000 - FN: 61.0000\n",
            "Epoch 7/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0699 - accuracy: 0.9748 - precision: 0.9758 - recall: 0.9737 - TP: 2220.0000 - TN: 2223.0000 - FP: 55.0000 - FN: 60.0000\n",
            "Epoch 8/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0823 - accuracy: 0.9686 - precision: 0.9717 - recall: 0.9654 - TP: 2201.0000 - TN: 2214.0000 - FP: 64.0000 - FN: 79.0000\n",
            "Epoch 9/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0849 - accuracy: 0.9680 - precision: 0.9705 - recall: 0.9654 - TP: 2201.0000 - TN: 2211.0000 - FP: 67.0000 - FN: 79.0000\n",
            "Epoch 10/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0627 - accuracy: 0.9763 - precision: 0.9772 - recall: 0.9754 - TP: 2224.0000 - TN: 2226.0000 - FP: 52.0000 - FN: 56.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "285/285 [==============================] - 5s 13ms/step - loss: 0.5077 - accuracy: 0.8783 - precision: 0.8752 - recall: 0.8825 - TP: 2012.0000 - TN: 1992.0000 - FP: 287.0000 - FN: 268.0000\n",
            "Epoch 2/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1581 - accuracy: 0.9465 - precision: 0.9445 - recall: 0.9487 - TP: 2163.0000 - TN: 2152.0000 - FP: 127.0000 - FN: 117.0000\n",
            "Epoch 3/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1498 - accuracy: 0.9449 - precision: 0.9444 - recall: 0.9456 - TP: 2156.0000 - TN: 2152.0000 - FP: 127.0000 - FN: 124.0000\n",
            "Epoch 4/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1065 - accuracy: 0.9612 - precision: 0.9638 - recall: 0.9583 - TP: 2185.0000 - TN: 2197.0000 - FP: 82.0000 - FN: 95.0000\n",
            "Epoch 5/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0949 - accuracy: 0.9634 - precision: 0.9640 - recall: 0.9627 - TP: 2195.0000 - TN: 2197.0000 - FP: 82.0000 - FN: 85.0000\n",
            "Epoch 6/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0812 - accuracy: 0.9719 - precision: 0.9736 - recall: 0.9702 - TP: 2212.0000 - TN: 2219.0000 - FP: 60.0000 - FN: 68.0000\n",
            "Epoch 7/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0851 - accuracy: 0.9680 - precision: 0.9672 - recall: 0.9689 - TP: 2209.0000 - TN: 2204.0000 - FP: 75.0000 - FN: 71.0000\n",
            "Epoch 8/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0824 - accuracy: 0.9693 - precision: 0.9705 - recall: 0.9680 - TP: 2207.0000 - TN: 2212.0000 - FP: 67.0000 - FN: 73.0000\n",
            "Epoch 9/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0730 - accuracy: 0.9743 - precision: 0.9775 - recall: 0.9711 - TP: 2214.0000 - TN: 2228.0000 - FP: 51.0000 - FN: 66.0000\n",
            "Epoch 10/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0517 - accuracy: 0.9831 - precision: 0.9855 - recall: 0.9807 - TP: 2236.0000 - TN: 2246.0000 - FP: 33.0000 - FN: 44.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "285/285 [==============================] - 6s 13ms/step - loss: 0.5467 - accuracy: 0.8769 - precision: 0.8729 - recall: 0.8825 - TP: 2012.0000 - TN: 1986.0000 - FP: 293.0000 - FN: 268.0000\n",
            "Epoch 2/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1580 - accuracy: 0.9417 - precision: 0.9367 - recall: 0.9474 - TP: 2160.0000 - TN: 2133.0000 - FP: 146.0000 - FN: 120.0000\n",
            "Epoch 3/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1154 - accuracy: 0.9579 - precision: 0.9599 - recall: 0.9557 - TP: 2179.0000 - TN: 2188.0000 - FP: 91.0000 - FN: 101.0000\n",
            "Epoch 4/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.1079 - accuracy: 0.9583 - precision: 0.9628 - recall: 0.9535 - TP: 2174.0000 - TN: 2195.0000 - FP: 84.0000 - FN: 106.0000\n",
            "Epoch 5/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0945 - accuracy: 0.9653 - precision: 0.9662 - recall: 0.9645 - TP: 2199.0000 - TN: 2202.0000 - FP: 77.0000 - FN: 81.0000\n",
            "Epoch 6/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0801 - accuracy: 0.9715 - precision: 0.9732 - recall: 0.9697 - TP: 2211.0000 - TN: 2218.0000 - FP: 61.0000 - FN: 69.0000\n",
            "Epoch 7/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0754 - accuracy: 0.9713 - precision: 0.9731 - recall: 0.9693 - TP: 2210.0000 - TN: 2218.0000 - FP: 61.0000 - FN: 70.0000\n",
            "Epoch 8/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0683 - accuracy: 0.9743 - precision: 0.9750 - recall: 0.9737 - TP: 2220.0000 - TN: 2222.0000 - FP: 57.0000 - FN: 60.0000\n",
            "Epoch 9/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0550 - accuracy: 0.9794 - precision: 0.9815 - recall: 0.9772 - TP: 2228.0000 - TN: 2237.0000 - FP: 42.0000 - FN: 52.0000\n",
            "Epoch 10/10\n",
            "285/285 [==============================] - 4s 13ms/step - loss: 0.0598 - accuracy: 0.9774 - precision: 0.9785 - recall: 0.9763 - TP: 2226.0000 - TN: 2230.0000 - FP: 49.0000 - FN: 54.0000\n",
            "72/72 [==============================] - 1s 8ms/step\n",
            "Epoch 1/5\n",
            "143/143 [==============================] - 4s 19ms/step - loss: 0.3146 - accuracy: 0.8673 - precision: 0.8553 - recall: 0.8842 - TP: 2016.0000 - TN: 1937.0000 - FP: 341.0000 - FN: 264.0000\n",
            "Epoch 2/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1538 - accuracy: 0.9412 - precision: 0.9374 - recall: 0.9456 - TP: 2156.0000 - TN: 2134.0000 - FP: 144.0000 - FN: 124.0000\n",
            "Epoch 3/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1063 - accuracy: 0.9640 - precision: 0.9612 - recall: 0.9671 - TP: 2205.0000 - TN: 2189.0000 - FP: 89.0000 - FN: 75.0000\n",
            "Epoch 4/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0841 - accuracy: 0.9704 - precision: 0.9685 - recall: 0.9724 - TP: 2217.0000 - TN: 2206.0000 - FP: 72.0000 - FN: 63.0000\n",
            "Epoch 5/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0602 - accuracy: 0.9787 - precision: 0.9794 - recall: 0.9781 - TP: 2230.0000 - TN: 2231.0000 - FP: 47.0000 - FN: 50.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "143/143 [==============================] - 4s 19ms/step - loss: 0.3232 - accuracy: 0.8671 - precision: 0.8511 - recall: 0.8899 - TP: 2029.0000 - TN: 1924.0000 - FP: 355.0000 - FN: 251.0000\n",
            "Epoch 2/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1493 - accuracy: 0.9456 - precision: 0.9406 - recall: 0.9513 - TP: 2169.0000 - TN: 2142.0000 - FP: 137.0000 - FN: 111.0000\n",
            "Epoch 3/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1194 - accuracy: 0.9585 - precision: 0.9584 - recall: 0.9588 - TP: 2186.0000 - TN: 2184.0000 - FP: 95.0000 - FN: 94.0000\n",
            "Epoch 4/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1013 - accuracy: 0.9629 - precision: 0.9623 - recall: 0.9636 - TP: 2197.0000 - TN: 2193.0000 - FP: 86.0000 - FN: 83.0000\n",
            "Epoch 5/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0706 - accuracy: 0.9765 - precision: 0.9751 - recall: 0.9781 - TP: 2230.0000 - TN: 2222.0000 - FP: 57.0000 - FN: 50.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "143/143 [==============================] - 4s 19ms/step - loss: 0.3212 - accuracy: 0.8620 - precision: 0.8535 - recall: 0.8741 - TP: 1993.0000 - TN: 1937.0000 - FP: 342.0000 - FN: 287.0000\n",
            "Epoch 2/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1354 - accuracy: 0.9454 - precision: 0.9421 - recall: 0.9491 - TP: 2164.0000 - TN: 2146.0000 - FP: 133.0000 - FN: 116.0000\n",
            "Epoch 3/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1070 - accuracy: 0.9583 - precision: 0.9579 - recall: 0.9588 - TP: 2186.0000 - TN: 2183.0000 - FP: 96.0000 - FN: 94.0000\n",
            "Epoch 4/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0768 - accuracy: 0.9686 - precision: 0.9680 - recall: 0.9693 - TP: 2210.0000 - TN: 2206.0000 - FP: 73.0000 - FN: 70.0000\n",
            "Epoch 5/5\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0553 - accuracy: 0.9800 - precision: 0.9803 - recall: 0.9798 - TP: 2234.0000 - TN: 2234.0000 - FP: 45.0000 - FN: 46.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "143/143 [==============================] - 4s 20ms/step - loss: 0.5735 - accuracy: 0.8802 - precision: 0.8836 - recall: 0.8759 - TP: 1997.0000 - TN: 2015.0000 - FP: 263.0000 - FN: 283.0000\n",
            "Epoch 2/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.2197 - accuracy: 0.9353 - precision: 0.9382 - recall: 0.9320 - TP: 2125.0000 - TN: 2138.0000 - FP: 140.0000 - FN: 155.0000\n",
            "Epoch 3/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1517 - accuracy: 0.9467 - precision: 0.9450 - recall: 0.9487 - TP: 2163.0000 - TN: 2152.0000 - FP: 126.0000 - FN: 117.0000\n",
            "Epoch 4/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1024 - accuracy: 0.9620 - precision: 0.9639 - recall: 0.9601 - TP: 2189.0000 - TN: 2196.0000 - FP: 82.0000 - FN: 91.0000\n",
            "Epoch 5/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0790 - accuracy: 0.9713 - precision: 0.9723 - recall: 0.9702 - TP: 2212.0000 - TN: 2215.0000 - FP: 63.0000 - FN: 68.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "143/143 [==============================] - 5s 20ms/step - loss: 0.6225 - accuracy: 0.8866 - precision: 0.8871 - recall: 0.8860 - TP: 2020.0000 - TN: 2022.0000 - FP: 257.0000 - FN: 260.0000\n",
            "Epoch 2/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1769 - accuracy: 0.9434 - precision: 0.9454 - recall: 0.9412 - TP: 2146.0000 - TN: 2155.0000 - FP: 124.0000 - FN: 134.0000\n",
            "Epoch 3/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1270 - accuracy: 0.9550 - precision: 0.9577 - recall: 0.9522 - TP: 2171.0000 - TN: 2183.0000 - FP: 96.0000 - FN: 109.0000\n",
            "Epoch 4/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1060 - accuracy: 0.9621 - precision: 0.9643 - recall: 0.9596 - TP: 2188.0000 - TN: 2198.0000 - FP: 81.0000 - FN: 92.0000\n",
            "Epoch 5/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0815 - accuracy: 0.9704 - precision: 0.9702 - recall: 0.9706 - TP: 2213.0000 - TN: 2211.0000 - FP: 68.0000 - FN: 67.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/5\n",
            "143/143 [==============================] - 5s 20ms/step - loss: 0.4788 - accuracy: 0.8870 - precision: 0.8862 - recall: 0.8882 - TP: 2025.0000 - TN: 2019.0000 - FP: 260.0000 - FN: 255.0000\n",
            "Epoch 2/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1519 - accuracy: 0.9465 - precision: 0.9477 - recall: 0.9452 - TP: 2155.0000 - TN: 2160.0000 - FP: 119.0000 - FN: 125.0000\n",
            "Epoch 3/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1434 - accuracy: 0.9460 - precision: 0.9472 - recall: 0.9447 - TP: 2154.0000 - TN: 2159.0000 - FP: 120.0000 - FN: 126.0000\n",
            "Epoch 4/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0899 - accuracy: 0.9662 - precision: 0.9658 - recall: 0.9667 - TP: 2204.0000 - TN: 2201.0000 - FP: 78.0000 - FN: 76.0000\n",
            "Epoch 5/5\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0897 - accuracy: 0.9662 - precision: 0.9670 - recall: 0.9654 - TP: 2201.0000 - TN: 2204.0000 - FP: 75.0000 - FN: 79.0000\n",
            "72/72 [==============================] - 1s 8ms/step\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 4s 19ms/step - loss: 0.3133 - accuracy: 0.8703 - precision: 0.8648 - recall: 0.8781 - TP: 2002.0000 - TN: 1965.0000 - FP: 313.0000 - FN: 278.0000\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1449 - accuracy: 0.9458 - precision: 0.9425 - recall: 0.9496 - TP: 2165.0000 - TN: 2146.0000 - FP: 132.0000 - FN: 115.0000\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1112 - accuracy: 0.9623 - precision: 0.9599 - recall: 0.9649 - TP: 2200.0000 - TN: 2186.0000 - FP: 92.0000 - FN: 80.0000\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0871 - accuracy: 0.9706 - precision: 0.9690 - recall: 0.9724 - TP: 2217.0000 - TN: 2207.0000 - FP: 71.0000 - FN: 63.0000\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0622 - accuracy: 0.9794 - precision: 0.9802 - recall: 0.9785 - TP: 2231.0000 - TN: 2233.0000 - FP: 45.0000 - FN: 49.0000\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0625 - accuracy: 0.9792 - precision: 0.9802 - recall: 0.9781 - TP: 2230.0000 - TN: 2233.0000 - FP: 45.0000 - FN: 50.0000\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0490 - accuracy: 0.9829 - precision: 0.9820 - recall: 0.9838 - TP: 2243.0000 - TN: 2237.0000 - FP: 41.0000 - FN: 37.0000\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0288 - accuracy: 0.9910 - precision: 0.9943 - recall: 0.9877 - TP: 2252.0000 - TN: 2265.0000 - FP: 13.0000 - FN: 28.0000\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0388 - accuracy: 0.9884 - precision: 0.9916 - recall: 0.9851 - TP: 2246.0000 - TN: 2259.0000 - FP: 19.0000 - FN: 34.0000\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0195 - accuracy: 0.9941 - precision: 0.9947 - recall: 0.9934 - TP: 2265.0000 - TN: 2266.0000 - FP: 12.0000 - FN: 15.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 4s 20ms/step - loss: 0.3095 - accuracy: 0.8644 - precision: 0.8524 - recall: 0.8816 - TP: 2010.0000 - TN: 1931.0000 - FP: 348.0000 - FN: 270.0000\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1445 - accuracy: 0.9482 - precision: 0.9451 - recall: 0.9518 - TP: 2170.0000 - TN: 2153.0000 - FP: 126.0000 - FN: 110.0000\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1127 - accuracy: 0.9585 - precision: 0.9575 - recall: 0.9596 - TP: 2188.0000 - TN: 2182.0000 - FP: 97.0000 - FN: 92.0000\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0968 - accuracy: 0.9640 - precision: 0.9616 - recall: 0.9667 - TP: 2204.0000 - TN: 2191.0000 - FP: 88.0000 - FN: 76.0000\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0657 - accuracy: 0.9770 - precision: 0.9772 - recall: 0.9768 - TP: 2227.0000 - TN: 2227.0000 - FP: 52.0000 - FN: 53.0000\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0616 - accuracy: 0.9789 - precision: 0.9785 - recall: 0.9794 - TP: 2233.0000 - TN: 2230.0000 - FP: 49.0000 - FN: 47.0000\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0432 - accuracy: 0.9864 - precision: 0.9877 - recall: 0.9851 - TP: 2246.0000 - TN: 2251.0000 - FP: 28.0000 - FN: 34.0000\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0349 - accuracy: 0.9890 - precision: 0.9895 - recall: 0.9886 - TP: 2254.0000 - TN: 2255.0000 - FP: 24.0000 - FN: 26.0000\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0254 - accuracy: 0.9921 - precision: 0.9943 - recall: 0.9899 - TP: 2257.0000 - TN: 2266.0000 - FP: 13.0000 - FN: 23.0000\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0188 - accuracy: 0.9945 - precision: 0.9960 - recall: 0.9930 - TP: 2264.0000 - TN: 2270.0000 - FP: 9.0000 - FN: 16.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 4s 19ms/step - loss: 0.3074 - accuracy: 0.8741 - precision: 0.8590 - recall: 0.8952 - TP: 2041.0000 - TN: 1944.0000 - FP: 335.0000 - FN: 239.0000\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1300 - accuracy: 0.9526 - precision: 0.9475 - recall: 0.9583 - TP: 2185.0000 - TN: 2158.0000 - FP: 121.0000 - FN: 95.0000\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.1012 - accuracy: 0.9605 - precision: 0.9605 - recall: 0.9605 - TP: 2190.0000 - TN: 2189.0000 - FP: 90.0000 - FN: 90.0000\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0661 - accuracy: 0.9730 - precision: 0.9728 - recall: 0.9732 - TP: 2219.0000 - TN: 2217.0000 - FP: 62.0000 - FN: 61.0000\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0515 - accuracy: 0.9820 - precision: 0.9833 - recall: 0.9807 - TP: 2236.0000 - TN: 2241.0000 - FP: 38.0000 - FN: 44.0000\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0394 - accuracy: 0.9862 - precision: 0.9877 - recall: 0.9846 - TP: 2245.0000 - TN: 2251.0000 - FP: 28.0000 - FN: 35.0000\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0281 - accuracy: 0.9917 - precision: 0.9934 - recall: 0.9899 - TP: 2257.0000 - TN: 2264.0000 - FP: 15.0000 - FN: 23.0000\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0766 - accuracy: 0.9787 - precision: 0.9781 - recall: 0.9794 - TP: 2233.0000 - TN: 2229.0000 - FP: 50.0000 - FN: 47.0000\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0474 - accuracy: 0.9825 - precision: 0.9850 - recall: 0.9798 - TP: 2234.0000 - TN: 2245.0000 - FP: 34.0000 - FN: 46.0000\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 3s 19ms/step - loss: 0.0194 - accuracy: 0.9950 - precision: 0.9956 - recall: 0.9943 - TP: 2267.0000 - TN: 2269.0000 - FP: 10.0000 - FN: 13.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 5s 20ms/step - loss: 0.4301 - accuracy: 0.8914 - precision: 0.8889 - recall: 0.8947 - TP: 2040.0000 - TN: 2023.0000 - FP: 255.0000 - FN: 240.0000\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1867 - accuracy: 0.9394 - precision: 0.9399 - recall: 0.9390 - TP: 2141.0000 - TN: 2141.0000 - FP: 137.0000 - FN: 139.0000\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1181 - accuracy: 0.9563 - precision: 0.9558 - recall: 0.9570 - TP: 2182.0000 - TN: 2177.0000 - FP: 101.0000 - FN: 98.0000\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1017 - accuracy: 0.9623 - precision: 0.9607 - recall: 0.9640 - TP: 2198.0000 - TN: 2188.0000 - FP: 90.0000 - FN: 82.0000\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1005 - accuracy: 0.9631 - precision: 0.9619 - recall: 0.9645 - TP: 2199.0000 - TN: 2191.0000 - FP: 87.0000 - FN: 81.0000\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0816 - accuracy: 0.9691 - precision: 0.9697 - recall: 0.9684 - TP: 2208.0000 - TN: 2209.0000 - FP: 69.0000 - FN: 72.0000\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0692 - accuracy: 0.9721 - precision: 0.9732 - recall: 0.9711 - TP: 2214.0000 - TN: 2217.0000 - FP: 61.0000 - FN: 66.0000\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0746 - accuracy: 0.9737 - precision: 0.9745 - recall: 0.9728 - TP: 2218.0000 - TN: 2220.0000 - FP: 58.0000 - FN: 62.0000\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0572 - accuracy: 0.9778 - precision: 0.9776 - recall: 0.9781 - TP: 2230.0000 - TN: 2227.0000 - FP: 51.0000 - FN: 50.0000\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0494 - accuracy: 0.9814 - precision: 0.9828 - recall: 0.9798 - TP: 2234.0000 - TN: 2239.0000 - FP: 39.0000 - FN: 46.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 5s 20ms/step - loss: 0.6693 - accuracy: 0.8807 - precision: 0.8831 - recall: 0.8776 - TP: 2001.0000 - TN: 2014.0000 - FP: 265.0000 - FN: 279.0000\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1976 - accuracy: 0.9344 - precision: 0.9331 - recall: 0.9360 - TP: 2134.0000 - TN: 2126.0000 - FP: 153.0000 - FN: 146.0000\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1355 - accuracy: 0.9491 - precision: 0.9507 - recall: 0.9474 - TP: 2160.0000 - TN: 2167.0000 - FP: 112.0000 - FN: 120.0000\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1149 - accuracy: 0.9607 - precision: 0.9585 - recall: 0.9632 - TP: 2196.0000 - TN: 2184.0000 - FP: 95.0000 - FN: 84.0000\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0879 - accuracy: 0.9684 - precision: 0.9692 - recall: 0.9675 - TP: 2206.0000 - TN: 2209.0000 - FP: 70.0000 - FN: 74.0000\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0734 - accuracy: 0.9750 - precision: 0.9779 - recall: 0.9719 - TP: 2216.0000 - TN: 2229.0000 - FP: 50.0000 - FN: 64.0000\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0685 - accuracy: 0.9748 - precision: 0.9750 - recall: 0.9746 - TP: 2222.0000 - TN: 2222.0000 - FP: 57.0000 - FN: 58.0000\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0575 - accuracy: 0.9822 - precision: 0.9846 - recall: 0.9798 - TP: 2234.0000 - TN: 2244.0000 - FP: 35.0000 - FN: 46.0000\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0574 - accuracy: 0.9800 - precision: 0.9828 - recall: 0.9772 - TP: 2228.0000 - TN: 2240.0000 - FP: 39.0000 - FN: 52.0000\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0482 - accuracy: 0.9835 - precision: 0.9846 - recall: 0.9825 - TP: 2240.0000 - TN: 2244.0000 - FP: 35.0000 - FN: 40.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 5s 20ms/step - loss: 0.4454 - accuracy: 0.8769 - precision: 0.8700 - recall: 0.8864 - TP: 2021.0000 - TN: 1977.0000 - FP: 302.0000 - FN: 259.0000\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1499 - accuracy: 0.9452 - precision: 0.9448 - recall: 0.9456 - TP: 2156.0000 - TN: 2153.0000 - FP: 126.0000 - FN: 124.0000\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1363 - accuracy: 0.9500 - precision: 0.9508 - recall: 0.9491 - TP: 2164.0000 - TN: 2167.0000 - FP: 112.0000 - FN: 116.0000\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.1112 - accuracy: 0.9592 - precision: 0.9608 - recall: 0.9575 - TP: 2183.0000 - TN: 2190.0000 - FP: 89.0000 - FN: 97.0000\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0905 - accuracy: 0.9669 - precision: 0.9667 - recall: 0.9671 - TP: 2205.0000 - TN: 2203.0000 - FP: 76.0000 - FN: 75.0000\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0718 - accuracy: 0.9728 - precision: 0.9753 - recall: 0.9702 - TP: 2212.0000 - TN: 2223.0000 - FP: 56.0000 - FN: 68.0000\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0621 - accuracy: 0.9772 - precision: 0.9780 - recall: 0.9763 - TP: 2226.0000 - TN: 2229.0000 - FP: 50.0000 - FN: 54.0000\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0493 - accuracy: 0.9800 - precision: 0.9815 - recall: 0.9785 - TP: 2231.0000 - TN: 2237.0000 - FP: 42.0000 - FN: 49.0000\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0731 - accuracy: 0.9737 - precision: 0.9745 - recall: 0.9728 - TP: 2218.0000 - TN: 2221.0000 - FP: 58.0000 - FN: 62.0000\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 3s 20ms/step - loss: 0.0497 - accuracy: 0.9807 - precision: 0.9794 - recall: 0.9820 - TP: 2239.0000 - TN: 2232.0000 - FP: 47.0000 - FN: 41.0000\n",
            "72/72 [==============================] - 1s 7ms/step\n",
            "Epoch 1/10\n",
            "214/214 [==============================] - 6s 20ms/step - loss: 0.2849 - accuracy: 0.8839 - precision: 0.8741 - recall: 0.8971 - TP: 3068.0000 - TN: 2976.0000 - FP: 442.0000 - FN: 352.0000\n",
            "Epoch 2/10\n",
            "214/214 [==============================] - 4s 19ms/step - loss: 0.1218 - accuracy: 0.9554 - precision: 0.9534 - recall: 0.9576 - TP: 3275.0000 - TN: 3258.0000 - FP: 160.0000 - FN: 145.0000\n",
            "Epoch 3/10\n",
            "214/214 [==============================] - 4s 19ms/step - loss: 0.0924 - accuracy: 0.9683 - precision: 0.9692 - recall: 0.9673 - TP: 3308.0000 - TN: 3313.0000 - FP: 105.0000 - FN: 112.0000\n",
            "Epoch 4/10\n",
            "214/214 [==============================] - 4s 19ms/step - loss: 0.0765 - accuracy: 0.9694 - precision: 0.9699 - recall: 0.9690 - TP: 3314.0000 - TN: 3315.0000 - FP: 103.0000 - FN: 106.0000\n",
            "Epoch 5/10\n",
            "214/214 [==============================] - 4s 19ms/step - loss: 0.0653 - accuracy: 0.9767 - precision: 0.9752 - recall: 0.9784 - TP: 3346.0000 - TN: 3333.0000 - FP: 85.0000 - FN: 74.0000\n",
            "Epoch 6/10\n",
            "214/214 [==============================] - 4s 19ms/step - loss: 0.0485 - accuracy: 0.9823 - precision: 0.9825 - recall: 0.9822 - TP: 3359.0000 - TN: 3358.0000 - FP: 60.0000 - FN: 61.0000\n",
            "Epoch 7/10\n",
            "214/214 [==============================] - 4s 20ms/step - loss: 0.0352 - accuracy: 0.9887 - precision: 0.9892 - recall: 0.9883 - TP: 3380.0000 - TN: 3381.0000 - FP: 37.0000 - FN: 40.0000\n",
            "Epoch 8/10\n",
            "214/214 [==============================] - 4s 20ms/step - loss: 0.0380 - accuracy: 0.9871 - precision: 0.9871 - recall: 0.9871 - TP: 3376.0000 - TN: 3374.0000 - FP: 44.0000 - FN: 44.0000\n",
            "Epoch 9/10\n",
            "214/214 [==============================] - 4s 19ms/step - loss: 0.0215 - accuracy: 0.9931 - precision: 0.9939 - recall: 0.9924 - TP: 3394.0000 - TN: 3397.0000 - FP: 21.0000 - FN: 26.0000\n",
            "Epoch 10/10\n",
            "214/214 [==============================] - 4s 19ms/step - loss: 0.0271 - accuracy: 0.9902 - precision: 0.9898 - recall: 0.9906 - TP: 3388.0000 - TN: 3383.0000 - FP: 35.0000 - FN: 32.0000\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674771682411
        },
        "id": "Jb4DkgWuxMzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587ef24a-57ee-4587-9233-67c9fe975086"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the best Model\n",
        "print(\"Best: %f using %s\" % (grid_model.best_score_, grid_model.best_params_))\n",
        "\n",
        "# print all experiment results\n",
        "import pandas as pd\n",
        "results = pd.DataFrame(grid_model.cv_results_)\n",
        "results"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.963876 using {'batch_size': 32, 'epochs': 10, 'optimizer': 'SGD'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0      21.022145      0.057674         1.261626        0.025074   \n",
              "1      22.139889      0.123384         1.244888        0.016963   \n",
              "2      38.600697      0.246057         1.231761        0.010854   \n",
              "3      40.460346      0.083299         1.253082        0.022977   \n",
              "4      17.402385      0.032225         1.240948        0.010374   \n",
              "5      18.116621      0.201200         1.248540        0.027881   \n",
              "6      31.528409      0.222297         1.251847        0.008125   \n",
              "7      32.457918      0.017717         1.249578        0.015695   \n",
              "\n",
              "  param_batch_size param_epochs param_optimizer  \\\n",
              "0               16            5             SGD   \n",
              "1               16            5            adam   \n",
              "2               16           10             SGD   \n",
              "3               16           10            adam   \n",
              "4               32            5             SGD   \n",
              "5               32            5            adam   \n",
              "6               32           10             SGD   \n",
              "7               32           10            adam   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "0  {'batch_size': 16, 'epochs': 5, 'optimizer': '...           0.972368   \n",
              "1  {'batch_size': 16, 'epochs': 5, 'optimizer': '...           0.561842   \n",
              "2  {'batch_size': 16, 'epochs': 10, 'optimizer': ...           0.948684   \n",
              "3  {'batch_size': 16, 'epochs': 10, 'optimizer': ...           0.965351   \n",
              "4  {'batch_size': 32, 'epochs': 5, 'optimizer': '...           0.970175   \n",
              "5  {'batch_size': 32, 'epochs': 5, 'optimizer': '...           0.946491   \n",
              "6  {'batch_size': 32, 'epochs': 10, 'optimizer': ...           0.978947   \n",
              "7  {'batch_size': 32, 'epochs': 10, 'optimizer': ...           0.957018   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "0           0.953927           0.960070         0.962122        0.007667   \n",
              "1           0.912242           0.893813         0.789299        0.161012   \n",
              "2           0.966213           0.954366         0.956421        0.007302   \n",
              "3           0.964458           0.501097         0.810302        0.218641   \n",
              "4           0.953050           0.907416         0.943547        0.026488   \n",
              "5           0.955244           0.874068         0.925267        0.036380   \n",
              "6           0.968407           0.944274         0.963876        0.014513   \n",
              "7           0.963581           0.956121         0.958906        0.003325   \n",
              "\n",
              "   rank_test_score  \n",
              "0                2  \n",
              "1                8  \n",
              "2                4  \n",
              "3                7  \n",
              "4                5  \n",
              "5                6  \n",
              "6                1  \n",
              "7                3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d6c7216-7675-4090-aaf8-5e3c0e656584\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_batch_size</th>\n",
              "      <th>param_epochs</th>\n",
              "      <th>param_optimizer</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21.022145</td>\n",
              "      <td>0.057674</td>\n",
              "      <td>1.261626</td>\n",
              "      <td>0.025074</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>SGD</td>\n",
              "      <td>{'batch_size': 16, 'epochs': 5, 'optimizer': '...</td>\n",
              "      <td>0.972368</td>\n",
              "      <td>0.953927</td>\n",
              "      <td>0.960070</td>\n",
              "      <td>0.962122</td>\n",
              "      <td>0.007667</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.139889</td>\n",
              "      <td>0.123384</td>\n",
              "      <td>1.244888</td>\n",
              "      <td>0.016963</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'batch_size': 16, 'epochs': 5, 'optimizer': '...</td>\n",
              "      <td>0.561842</td>\n",
              "      <td>0.912242</td>\n",
              "      <td>0.893813</td>\n",
              "      <td>0.789299</td>\n",
              "      <td>0.161012</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38.600697</td>\n",
              "      <td>0.246057</td>\n",
              "      <td>1.231761</td>\n",
              "      <td>0.010854</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>SGD</td>\n",
              "      <td>{'batch_size': 16, 'epochs': 10, 'optimizer': ...</td>\n",
              "      <td>0.948684</td>\n",
              "      <td>0.966213</td>\n",
              "      <td>0.954366</td>\n",
              "      <td>0.956421</td>\n",
              "      <td>0.007302</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40.460346</td>\n",
              "      <td>0.083299</td>\n",
              "      <td>1.253082</td>\n",
              "      <td>0.022977</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'batch_size': 16, 'epochs': 10, 'optimizer': ...</td>\n",
              "      <td>0.965351</td>\n",
              "      <td>0.964458</td>\n",
              "      <td>0.501097</td>\n",
              "      <td>0.810302</td>\n",
              "      <td>0.218641</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.402385</td>\n",
              "      <td>0.032225</td>\n",
              "      <td>1.240948</td>\n",
              "      <td>0.010374</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>SGD</td>\n",
              "      <td>{'batch_size': 32, 'epochs': 5, 'optimizer': '...</td>\n",
              "      <td>0.970175</td>\n",
              "      <td>0.953050</td>\n",
              "      <td>0.907416</td>\n",
              "      <td>0.943547</td>\n",
              "      <td>0.026488</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18.116621</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>1.248540</td>\n",
              "      <td>0.027881</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'batch_size': 32, 'epochs': 5, 'optimizer': '...</td>\n",
              "      <td>0.946491</td>\n",
              "      <td>0.955244</td>\n",
              "      <td>0.874068</td>\n",
              "      <td>0.925267</td>\n",
              "      <td>0.036380</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>31.528409</td>\n",
              "      <td>0.222297</td>\n",
              "      <td>1.251847</td>\n",
              "      <td>0.008125</td>\n",
              "      <td>32</td>\n",
              "      <td>10</td>\n",
              "      <td>SGD</td>\n",
              "      <td>{'batch_size': 32, 'epochs': 10, 'optimizer': ...</td>\n",
              "      <td>0.978947</td>\n",
              "      <td>0.968407</td>\n",
              "      <td>0.944274</td>\n",
              "      <td>0.963876</td>\n",
              "      <td>0.014513</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>32.457918</td>\n",
              "      <td>0.017717</td>\n",
              "      <td>1.249578</td>\n",
              "      <td>0.015695</td>\n",
              "      <td>32</td>\n",
              "      <td>10</td>\n",
              "      <td>adam</td>\n",
              "      <td>{'batch_size': 32, 'epochs': 10, 'optimizer': ...</td>\n",
              "      <td>0.957018</td>\n",
              "      <td>0.963581</td>\n",
              "      <td>0.956121</td>\n",
              "      <td>0.958906</td>\n",
              "      <td>0.003325</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d6c7216-7675-4090-aaf8-5e3c0e656584')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d6c7216-7675-4090-aaf8-5e3c0e656584 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d6c7216-7675-4090-aaf8-5e3c0e656584');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1674771683676
        },
        "id": "l7-UNIPBxMzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "477ce4ff-4675-4cb8-aa2e-5221970f3720"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the best value of precesion score\n",
        "print('Best Score: %s' % grid_model.best_score_)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(\"\\nBest parameters set:\")\n",
        "print(grid_model.best_params_)\n",
        "     "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.9638761229532805\n",
            "\n",
            "Best parameters set:\n",
            "{'batch_size': 32, 'epochs': 10, 'optimizer': 'SGD'}\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "7XU4vHfWxMzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab61e91-3f61-4ac8-845c-b599a9c65a7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# score on the refit data\n",
        "scores = grid_model.score(x_test, y_test)\n",
        "print(scores)\n",
        "\n",
        "# predict on the refit data\n",
        "predictions = grid_model.predict(x_test)\n",
        "print(predictions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 7ms/step\n",
            "0.959114139693356\n",
            "19/19 [==============================] - 0s 7ms/step\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "_2kGH0GjxMzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a770aca-0c7b-449c-8733-44d1eb87fa14"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-mSz8kxi-CB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}